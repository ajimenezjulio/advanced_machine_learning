{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Progress Summary: 3 classifiers (SVM, Log Reg, Multinomial NB) running on all data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reding data ( Stage 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import classifiers as clf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PhraseId  SentenceId                                             Phrase  \\\n",
      "0         1           1  A series of escapades demonstrating the adage ...   \n",
      "1         2           1  A series of escapades demonstrating the adage ...   \n",
      "2         3           1                                           A series   \n",
      "3         4           1                                                  A   \n",
      "4         5           1                                             series   \n",
      "\n",
      "   Sentiment  \n",
      "0          1  \n",
      "1          2  \n",
      "2          2  \n",
      "3          2  \n",
      "4          2  \n",
      "\n",
      "\n",
      "Comments size:  (156060,) \t Labels size:  (156060,)\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "df = pd.read_csv(current_dir + '/data/movie_reviews/train.tsv',encoding = \"ISO-8859-1\", sep='\\t')\n",
    "#print(df.info())\n",
    "print(df.head())\n",
    "\n",
    "# Spliting data to obtain comments and labels\n",
    "# Technically should also include summary at this point but ditched to save time\n",
    "\n",
    "#comments = df['Text']\n",
    "#score_label = df['Score']\n",
    "print('\\n\\nComments size: ', df['Phrase'].shape, \"\\t\", \"Labels size: \", df['Sentiment'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id comment_text toxic severe_toxic obscene threat insult identity_hate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOT SURE NECESSARY FOR THIS IMPLEMENTATION\n",
    "#toxic_labels = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data ( Stage 2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Downloading componnents of nltk (execute just one time nltk.download())\n",
    "# nltk.download()\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import string \n",
    "import pandas as pd \n",
    "from nltk import pos_tag \n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Function to preprocess the text data\n",
    "def preprocessing(text):\n",
    "    # Removing standar punctuation (replacing with blank \"\" spaces)\n",
    "    text2 = \" \".join(\"\".join([\" \" if ch in string.punctuation else ch for ch in text]).split())\n",
    "    \n",
    "    # Tokenizing the text into words (based on white spaces to build the list)\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text2) for word in nltk.word_tokenize(sent)]\n",
    "    \n",
    "    # Changing to lower case every word in the list to reduce duplicates\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    \n",
    "    # Removing english stop words from the list (stop words do not carry much weight in understanding the sentence)\n",
    "    stopwds = stopwords.words('english')\n",
    "    tokens = [token for token in tokens if token not in stopwds]\n",
    "    \n",
    "    # Removing words which length is lower than 3 (do not apport much of a meaning)\n",
    "    tokens = [word for word in tokens if len(word) >= 3]\n",
    "    \n",
    "    # Using PorterStemmer to stem suffixes in words\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    # Tagging the words\n",
    "    # “NN (noun, common, singular), NNP (noun, proper, singular), \n",
    "    # NNPS (noun, proper, plural), NNS (noun, common, plural), \n",
    "    # VB (verb, base form), VBD (verb, past tense), \n",
    "    # VBG (verb, present participle), VBN (verb, past participle), \n",
    "    # VBP (verb, present tense, not third person singular), \n",
    "    # VBZ (verb, present tense, third person singular)”\n",
    "    tagged_corpus = pos_tag(tokens)\n",
    "    Noun_tags = ['NN','NNP','NNPS','NNS']\n",
    "    Verb_tags = ['VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "    \n",
    "    # Lemmatizing model\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Validating tags and lemmatizing accordingly\n",
    "    def prat_lemmatize(token,tag):\n",
    "        # Nouns\n",
    "        if tag in Noun_tags:\n",
    "            return lemmatizer.lemmatize(token,'n')\n",
    "        # Verbs\n",
    "        elif tag in Verb_tags:\n",
    "            return lemmatizer.lemmatize(token,'v')\n",
    "        # Any other\n",
    "        else:\n",
    "            return lemmatizer.lemmatize(token,'n')\n",
    "    \n",
    "    # Reconstructing text\n",
    "    pre_proc_text =  \" \".join([prat_lemmatize(token,tag) for token,tag in tagged_corpus])             \n",
    "    # Return reconstructed text\n",
    "    return pre_proc_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess and storage process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from tqdm import tqdm\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "# Increasing depth in recursion limit\n",
    "#sys.setrecursionlimit(5000)\n",
    "\n",
    "# Initialising array to storage preprocessed data\n",
    "#preprocessed_data = []\n",
    "\n",
    "\n",
    "# Pre-processing\n",
    "\n",
    "#df['Phrase'] = df['Phrase'].apply(preprocessing)\n",
    "\n",
    "#i = 0\n",
    "#for line in tqdm(comments):\n",
    "#    i = i+1\n",
    "#    preprocessed_data.append(preprocessing(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving the preprocessed data\n",
    "#pickle_out = open(\"movie_preprocessed.pickle\",\"wb\")\n",
    "#pickle.dump(df, pickle_out)\n",
    "#pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting in training and test set ( Stage 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Importing preprocessed text data\n",
    "pickle_in = open(\"movie_preprocessed.pickle\",\"rb\")\n",
    "trainData = pickle.load(pickle_in)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    trainData['Phrase'], trainData['Sentiment'], test_size=0.2, random_state=37)\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(\n",
    "#    df['Phrase'], df['Sentiment'], test_size=0.2, random_state=37)\n",
    "\n",
    "\n",
    "print( \"Training set size:\\t\", len(x_train), \"\\nTest set size:\\t\\t\", len(x_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ys_train = toxic_labels.as_matrix()[0:train_size];\n",
    "#ys_test = toxic_labels.as_matrix()[train_size + 1:len(toxic_label)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing TF-IDF features ( Stage 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Vectorizer model \n",
    "# Ignoring terms with lower frequency than 2, range of sequences of words from 1 to 2,\n",
    "# most frequent 4000 words and normalising with l2\n",
    "vectorizer = TfidfVectorizer(min_df=2, ngram_range=(1, 2),  stop_words='english', \n",
    "                             max_features= 4000,strip_accents='unicode',  norm='l2')\n",
    "\n",
    "#vectorizer = CountVectorizer(min_df=2, ngram_range=(1, 2),  stop_words='english', \n",
    "#                             max_features= 4000,strip_accents='unicode')\n",
    "\n",
    "features_train = vectorizer.fit_transform(x_train).todense()\n",
    "features_test = vectorizer.transform(x_test).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying ( Stage 5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb_clf = MultinomialNB().fit(features_train, y_train)\n",
    "\n",
    "mnb_predicted_train = mnb_clf.predict(features_train)\n",
    "mnb_predicted_test = mnb_clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC #,SVC\n",
    "\n",
    "# c = penalty parameter\n",
    "c = 1.0\n",
    "svm_clf = LinearSVC(C = c).fit(features_train, y_train)\n",
    "\n",
    "svm_predicted_train = svm_clf.predict(features_train)\n",
    "svm_predicted_test = svm_clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CANOT CURRENTLY RUN THIS S NOT INSTALLED\n",
    "\n",
    "#from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Extreme Gradient Boost\n",
    "# md = Max depth\n",
    "# ss = Subsample ratio of training instance\n",
    "# cs = Subsample ratio of columns when constructing each tree\n",
    "\n",
    "#md = 1\n",
    "#ss = 0.8\n",
    "#cs = 0.8\n",
    "#clf = XGBClassifier( max_depth = md, subsample = ss,\n",
    "#                        colsample_bytree = cs).fit(features_train, y_train)\n",
    "\n",
    "#predicted_train = clf.predict(features_train)\n",
    "#predicted_test = clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# C = Inverse of regularization strength\n",
    "c = 1.0\n",
    "log_clf = LogisticRegression(C = c).fit(features_train, y_train)\n",
    "\n",
    "log_predicted_train = log_clf.predict(features_train)\n",
    "log_predicted_test = log_clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#### Random Forest\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnf_clf = RandomForestClassifier().fit(features_train, y_train)\n",
    "\n",
    "rnf_predicted_train = rnf_clf.predict(features_train)\n",
    "rnf_predicted_test = rnf_clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Ensemble for Classification\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import ensemble\n",
    "\n",
    "# create the sub models\n",
    "estimators = []\n",
    "estimators.append(('logistic', LogisticRegression()))\n",
    "estimators.append(('cart', DecisionTreeClassifier()))\n",
    "estimators.append(('svm', SVC()))\n",
    "\n",
    "# create the ensemble model\n",
    "## http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n",
    "clf = ensemble.VotingClassifier(estimators)\n",
    "clf.fit(features_train, y_train)\n",
    "\n",
    "## http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "# clf = ensemble.GradientBoostingClassifier(n_estimators=20, random_state=7, verbose=3)\n",
    "# clf.fit(features_train, y_train)\n",
    "\n",
    "## http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "# kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "# model = ensemble.AdaBoostClassifier(n_estimators=10, random_state=7)\n",
    "# results = model_selection.cross_val_score(model, features_train, y_train, cv=kfold)\n",
    "# print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics ( Stage 6 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes - Train Confusion Matrix\n",
      "\n",
      " Predicted    0     1      2     3    4\n",
      "Actual                                \n",
      "0          361  1891   3243   130    4\n",
      "1          106  4555  16504   614   15\n",
      "2           27  1476  59539  2501   55\n",
      "3            6   259  17334  8567  225\n",
      "4            0    22   3132  3555  727\n",
      "\n",
      "Naive Bayes- Train accuracy 0.591\n",
      "\n",
      "Naive Bayes  - Train Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.06      0.12      5629\n",
      "          1       0.56      0.21      0.30     21794\n",
      "          2       0.60      0.94      0.73     63598\n",
      "          3       0.56      0.32      0.41     26391\n",
      "          4       0.71      0.10      0.17      7436\n",
      "\n",
      "avg / total       0.59      0.59      0.53    124848\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Naive Bayes - Test Confusion Matrix\n",
      "\n",
      " Predicted   0     1      2     3    4\n",
      "Actual                               \n",
      "0          66   475    862    38    2\n",
      "1          31  1020   4272   147    9\n",
      "2          14   445  14855   662    8\n",
      "3           1    79   4340  2049   67\n",
      "4           1     2    772   855  140\n",
      "\n",
      "Naive Bayes- Test accuracy 0.581\n",
      "\n",
      "Naive Bayes  - Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.05      0.08      1443\n",
      "          1       0.50      0.19      0.27      5479\n",
      "          2       0.59      0.93      0.72     15984\n",
      "          3       0.55      0.31      0.40      6536\n",
      "          4       0.62      0.08      0.14      1770\n",
      "\n",
      "avg / total       0.57      0.58      0.51     31212\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "\n",
    "# Training confusion matrix\n",
    "print (\"\\nNaive Bayes - Train Confusion Matrix\\n\\n\",\n",
    "       pd.crosstab(y_train, mnb_predicted_train, rownames = [\"Actual\"], colnames = [\"Predicted\"]))\n",
    "# Training accuracy\n",
    "print (\"\\nNaive Bayes- Train accuracy\",\n",
    "       round(accuracy_score(y_train, mnb_predicted_train),3))\n",
    "# Training report\n",
    "print (\"\\nNaive Bayes  - Train Classification Report\\n\",\n",
    "       classification_report(y_train, mnb_predicted_train))\n",
    "\n",
    "print(\"------------------------------------------------------------\")\n",
    "\n",
    "# Test confusion matrix\n",
    "print (\"\\nNaive Bayes - Test Confusion Matrix\\n\\n\",\n",
    "       pd.crosstab(y_test,mnb_predicted_test,rownames = [\"Actual\"], colnames = [\"Predicted\"]))  \n",
    "# Test accuracy\n",
    "print (\"\\nNaive Bayes- Test accuracy\",\n",
    "       round(accuracy_score(y_test,mnb_predicted_test),3))\n",
    "# Test report\n",
    "print (\"\\nNaive Bayes  - Test Classification Report\\n\",\n",
    "       classification_report(y_test,mnb_predicted_test))\n",
    "\n",
    "print(\"------------------------------------------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM - Train Confusion Matrix\n",
      "\n",
      " Predicted     0     1      2      3     4\n",
      "Actual                                   \n",
      "0          1412  2429   1532    243    13\n",
      "1           596  8391  11435   1311    61\n",
      "2           205  3287  55795   4082   229\n",
      "3            49   819  11903  12757   863\n",
      "4             2    94   1256   3892  2192\n",
      "\n",
      "SVM- Train accuracy 0.645\n",
      "\n",
      "SVM  - Train Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.25      0.36      5629\n",
      "          1       0.56      0.39      0.46     21794\n",
      "          2       0.68      0.88      0.77     63598\n",
      "          3       0.57      0.48      0.52     26391\n",
      "          4       0.65      0.29      0.41      7436\n",
      "\n",
      "avg / total       0.63      0.65      0.62    124848\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "SVM - Test Confusion Matrix\n",
      "\n",
      " Predicted    0     1      2     3    4\n",
      "Actual                                \n",
      "0          253   670    436    76    8\n",
      "1          203  1818   3060   373   25\n",
      "2           57   942  13833  1107   45\n",
      "3           12   230   3108  2897  289\n",
      "4            3    22    345  1018  382\n",
      "\n",
      "SVM- Test accuracy 0.615\n",
      "\n",
      "SVM  - Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.18      0.26      1443\n",
      "          1       0.49      0.33      0.40      5479\n",
      "          2       0.67      0.87      0.75     15984\n",
      "          3       0.53      0.44      0.48      6536\n",
      "          4       0.51      0.22      0.30      1770\n",
      "\n",
      "avg / total       0.59      0.61      0.59     31212\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training confusion matrix\n",
    "print (\"\\nSVM - Train Confusion Matrix\\n\\n\",\n",
    "       pd.crosstab(y_train, svm_predicted_train, rownames = [\"Actual\"], colnames = [\"Predicted\"]))\n",
    "# Training accuracy\n",
    "print (\"\\nSVM- Train accuracy\",\n",
    "       round(accuracy_score(y_train, svm_predicted_train),3))\n",
    "# Training report\n",
    "print (\"\\nSVM  - Train Classification Report\\n\",\n",
    "       classification_report(y_train, svm_predicted_train))\n",
    "\n",
    "print(\"------------------------------------------------------------\")\n",
    "\n",
    "# Test confusion matrix\n",
    "print (\"\\nSVM - Test Confusion Matrix\\n\\n\",\n",
    "       pd.crosstab(y_test,svm_predicted_test,rownames = [\"Actual\"], colnames = [\"Predicted\"]))  \n",
    "# Test accuracy\n",
    "print (\"\\nSVM- Test accuracy\",\n",
    "       round(accuracy_score(y_test,svm_predicted_test),3))\n",
    "# Test report\n",
    "print (\"\\nSVM  - Test Classification Report\\n\",\n",
    "       classification_report(y_test,svm_predicted_test))\n",
    "\n",
    "print(\"------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression - Train Confusion Matrix\n",
      "\n",
      " Predicted    0     1      2      3     4\n",
      "Actual                                  \n",
      "0          980  2516   1868    253    12\n",
      "1          378  7432  12670   1273    41\n",
      "2          135  2609  57001   3672   181\n",
      "3           36   681  12896  12179   599\n",
      "4            2    88   1547   4120  1679\n",
      "\n",
      "Logistic Regression- Train accuracy 0.635\n",
      "\n",
      "Logistic Regression  - Train Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.17      0.27      5629\n",
      "          1       0.56      0.34      0.42     21794\n",
      "          2       0.66      0.90      0.76     63598\n",
      "          3       0.57      0.46      0.51     26391\n",
      "          4       0.67      0.23      0.34      7436\n",
      "\n",
      "avg / total       0.62      0.63      0.60    124848\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Logistic Regression - Test Confusion Matrix\n",
      "\n",
      " Predicted    0     1      2     3    4\n",
      "Actual                                \n",
      "0          180   662    511    85    5\n",
      "1          121  1646   3329   370   13\n",
      "2           40   760  14195   958   31\n",
      "3           10   194   3336  2796  200\n",
      "4            2    24    400  1033  311\n",
      "\n",
      "Logistic Regression- Test accuracy 0.613\n",
      "\n",
      "Logistic Regression  - Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.12      0.20      1443\n",
      "          1       0.50      0.30      0.38      5479\n",
      "          2       0.65      0.89      0.75     15984\n",
      "          3       0.53      0.43      0.47      6536\n",
      "          4       0.56      0.18      0.27      1770\n",
      "\n",
      "avg / total       0.59      0.61      0.57     31212\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training confusion matrix\n",
    "print (\"\\nLogistic Regression - Train Confusion Matrix\\n\\n\",\n",
    "       pd.crosstab(y_train, log_predicted_train, rownames = [\"Actual\"], colnames = [\"Predicted\"]))\n",
    "# Training accuracy\n",
    "print (\"\\nLogistic Regression- Train accuracy\",\n",
    "       round(accuracy_score(y_train, log_predicted_train),3))\n",
    "# Training report\n",
    "print (\"\\nLogistic Regression  - Train Classification Report\\n\",\n",
    "       classification_report(y_train, log_predicted_train))\n",
    "\n",
    "print(\"------------------------------------------------------------\")\n",
    "\n",
    "# Test confusion matrix\n",
    "print (\"\\nLogistic Regression - Test Confusion Matrix\\n\\n\",\n",
    "       pd.crosstab(y_test,log_predicted_test,rownames = [\"Actual\"], colnames = [\"Predicted\"]))  \n",
    "# Test accuracy\n",
    "print (\"\\nLogistic Regression- Test accuracy\",\n",
    "       round(accuracy_score(y_test,log_predicted_test),3))\n",
    "# Test report\n",
    "print (\"\\nLogistic Regression  - Test Classification Report\\n\",\n",
    "       classification_report(y_test,log_predicted_test))\n",
    "\n",
    "print(\"------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest - Train Confusion Matrix\n",
      "\n",
      " Predicted     0      1      2      3     4\n",
      "Actual                                    \n",
      "0          3804   1182    582     58     3\n",
      "1           836  14706   5845    384    23\n",
      "2           266   2558  57733   2861   180\n",
      "3            33    346   6253  18700  1059\n",
      "4             4     38    462   1739  5193\n",
      "\n",
      "Random Forest- Train accuracy 0.802\n",
      "\n",
      "Random Forest - Train Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.68      0.72      5629\n",
      "          1       0.78      0.67      0.72     21794\n",
      "          2       0.81      0.91      0.86     63598\n",
      "          3       0.79      0.71      0.75     26391\n",
      "          4       0.80      0.70      0.75      7436\n",
      "\n",
      "avg / total       0.80      0.80      0.80    124848\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Random Forest - Test Confusion Matrix\n",
      "\n",
      " Predicted    0     1      2     3    4\n",
      "Actual                                \n",
      "0          519   612    280    28    4\n",
      "1          480  2307   2434   240   18\n",
      "2          119  1412  12894  1468   91\n",
      "3           13   210   2501  3190  622\n",
      "4            2    20    205   867  676\n",
      "\n",
      "Random Forest - Test accuracy 0.628\n",
      "\n",
      "Random Forest - Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.46      0.36      0.40      1443\n",
      "          1       0.51      0.42      0.46      5479\n",
      "          2       0.70      0.81      0.75     15984\n",
      "          3       0.55      0.49      0.52      6536\n",
      "          4       0.48      0.38      0.43      1770\n",
      "\n",
      "avg / total       0.61      0.63      0.62     31212\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training confusion matrix\n",
    "print (\"\\nRandom Forest - Train Confusion Matrix\\n\\n\",\n",
    "       pd.crosstab(y_train, rnf_predicted_train, rownames = [\"Actual\"], colnames = [\"Predicted\"]))\n",
    "# Training accuracy\n",
    "print (\"\\nRandom Forest- Train accuracy\",\n",
    "       round(accuracy_score(y_train, rnf_predicted_train),3))\n",
    "# Training report\n",
    "print (\"\\nRandom Forest - Train Classification Report\\n\",\n",
    "       classification_report(y_train, rnf_predicted_train))\n",
    "\n",
    "print(\"------------------------------------------------------------\")\n",
    "\n",
    "# Test confusion matrix\n",
    "print (\"\\nRandom Forest - Test Confusion Matrix\\n\\n\",\n",
    "       pd.crosstab(y_test,rnf_predicted_test,rownames = [\"Actual\"], colnames = [\"Predicted\"]))  \n",
    "# Test accuracy\n",
    "print (\"\\nRandom Forest - Test accuracy\",\n",
    "       round(accuracy_score(y_test,rnf_predicted_test),3))\n",
    "# Test report\n",
    "print (\"\\nRandom Forest - Test Classification Report\\n\",\n",
    "       classification_report(y_test,rnf_predicted_test))\n",
    "\n",
    "print(\"------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Top 10 features - First ten & Last ten\n",
      "\n",
      "|\t-9.6672\t1960            \t\t|\t-4.4556\tmovi            |\n",
      "|\t-9.6672\t1999            \t\t|\t-4.5999\tbad             |\n",
      "|\t-9.6672\t20th            \t\t|\t-4.9988\tfilm            |\n",
      "|\t-9.6672\t20th centuri    \t\t|\t-5.4037\tlike            |\n",
      "|\t-9.6672\t50              \t\t|\t-5.4243\tminut           |\n",
      "|\t-9.6672\t60              \t\t|\t-5.4630\tmake            |\n",
      "|\t-9.6672\tacclaim         \t\t|\t-5.6182\tdull            |\n",
      "|\t-9.6672\taccomplish      \t\t|\t-5.6322\tworst           |\n",
      "|\t-9.6672\taccumul         \t\t|\t-5.7489\tbore            |\n",
      "|\t-9.6672\tach             \t\t|\t-5.7684\tcharact         |\n"
     ]
    }
   ],
   "source": [
    "# Getting feature names from vectorizer\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# Getting weights assigned to the features (it works only with linear kernels)\n",
    "# Empirical log probability of features given a class, P(x_i|y).\n",
    "coefs = mnb_clf.coef_\n",
    "\n",
    "# Smoothed empirical log probability for each class.\n",
    "intercept = mnb_clf.intercept_\n",
    "\n",
    "# Sorted coefs\n",
    "coefs_with_fns = sorted(zip(mnb_clf.coef_[0], feature_names))\n",
    "\n",
    "print (\"\\n\\nTop 10 features - First ten & Last ten\\n\")\n",
    "n = 10\n",
    "top_n_coefs = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "for (coef_1, fn_1), (coef_2, fn_2) in top_n_coefs:\n",
    "    # %-15s is for padding left\n",
    "    print('|\\t%.4f\\t%-16s\\t\\t|\\t%.4f\\t%-16s|' % (coef_1, fn_1, coef_2, fn_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15984"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_test == 2)\n",
    "#15984/31212\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
